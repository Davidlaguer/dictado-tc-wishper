import os
from dotenv import load_dotenv

# â€”â€”â€”â€”â€” Carga y verificaciÃ³n de la clave â€”â€”â€”â€”â€”
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("ğŸ”‘ La variable OPENAI_API_KEY no estÃ¡ definida en el entorno")
print("âœ… OPENAI_API_KEY detectada âœ…")

# â€”â€”â€”â€”â€” Imports del resto de dependencias â€”â€”â€”â€”â€”
import json
import tempfile
import subprocess
from flask import Flask, request, jsonify
from flask_cors import CORS
from flask_socketio import SocketIO, emit
import whisper
from openai import OpenAI

# â€”â€”â€”â€”â€” Inicializa cliente OpenAI â€”â€”â€”â€”â€”
client = OpenAI(api_key=api_key)

# â€”â€”â€”â€”â€” App y SocketIO â€”â€”â€”â€”â€”
app = Flask(
    __name__,
    static_folder=os.path.join(os.path.dirname(__file__), '../web'),
    static_url_path=''
)
CORS(app)
socketio = SocketIO(app, cors_allowed_origins="*")

# Sirve index.html en la raÃ­z
@app.route('/')
def index():
    return app.send_static_file('index.html')

# Sirve cualquier otro archivo estÃ¡tico (CSS, JS, imÃ¡genesâ€¦)
@app.route('/<path:filename>')
def static_files(filename):
    return app.send_static_file(filename)

# â€”â€”â€”â€”â€” Whisper Streaming â€”â€”â€”â€”â€”
model = whisper.load_model("base")

@socketio.on('audio_chunk')
def handle_audio_chunk(data):
    audio_bytes = bytes(data['chunk'])
    with tempfile.TemporaryDirectory() as tmpdir:
        in_path = os.path.join(tmpdir, 'chunk.webm')
        with open(in_path, 'wb') as f:
            f.write(audio_bytes)
        wav_path = os.path.join(tmpdir, 'chunk.wav')
        subprocess.run(
            ["ffmpeg", "-i", in_path, "-ar", "16000", "-ac", "1", wav_path],
            check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )
        result = model.transcribe(wav_path, language="es", fp16=False)
        text = result.get('text', '').strip()
    emit('transcription', {'text': text})

# â€”â€”â€”â€”â€” GeneraciÃ³n de informe con GPT-4 â€”â€”â€”â€”â€”
@app.route('/informe', methods=['POST'])
def generar_informe():
    data = request.get_json() or {}
    dictado = data.get('dictado', '').strip()
    if not dictado:
        return jsonify(error="Dictado vacÃ­o"), 400

    messages = [
        {
            "role": "system",
            "content": """Eres un radiÃ³logo experto. Genera siempre un informe con este formato exacto:

TC DE {ESTUDIO}:

TÃ‰CNICA:
{TEXTO_DE_LA_TECNICA}

HALLAZGOS:
{TEXTO_DE_LOS_HALLAZGOS}

CONCLUSIÃ“N:
{TEXTO_DE_LA_CONCLUSION}

DevuÃ©lvelo **solo** como un objeto JSON con las claves:
{
  \"estudio\": \"...\",
  \"tecnica\": \"...\",
  \"hallazgos\": \"...\",
  \"conclusion\": \"...\"
}

No incluyas nada fuera de ese JSON."""
        },
        {"role": "user", "content": dictado}
    ]

    print("ğŸ“¤ [informe] Mensajes a OpenAI:", messages)
    resp = client.chat.completions.create(
        model="gpt-4",
        messages=messages,
        temperature=0.2,
        max_tokens=1200
    )
    print("ğŸ“¥ [informe] Respuesta completa:", resp)
    raw = resp.choices[0].message.content.strip()
    print("ğŸ“„ [informe] Contenido crudo:", raw)

    try:
        informe_json = json.loads(raw)
        return jsonify(informe=informe_json)
    except json.JSONDecodeError as e:
        print("âš ï¸ [informe] Error al parsear JSON de OpenAI:", e)
        print("âš ï¸ [informe] Raw recibido:", raw)
        return jsonify(error="Error al parsear JSON de OpenAI"), 500
    except Exception as e:
        print("âš ï¸ [informe] Otro error inesperado:", e)
        return jsonify(error=str(e)), 500

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5050))
    print(f"ğŸ”¥ Iniciando servidor WebSocket con Whisper y OpenAI (puerto {port})â€¦")
    socketio.run(app, host='0.0.0.0', port=port)
